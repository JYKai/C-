# 신경망을 위한 행렬연산과 병렬 프로그래밍

## GPU 활용하기

신경망에는 유닛이라는 신경망을 구축하는 최소 단위가 있으며, 방대한 수의 유닛을 설정해서 각 유닛에 대해 계산해야 한다.
- 신경망 계산에서는 구성할 유닛을 행렬로 나타낸다.
```c++
a[1000][1000];

for (int i = 0; i < 1000; i++)
{
    for (int j = 0; j < 1000; j++)
    {
        a[i][j] = 1;
    }
}
```
- 위의 방식은 CPU가 1000 x 1000의 계싼을 하나씩 차례로 처리하므로 O(n^2)의 연산량을 가지게 된다.
- 컴퓨터의 CPU는 병렬 연산 유닛(코어)을 탑재하고 있으므로, CPU와 코어 수에 따른 병렬 연산이 가능하다.
- 하지만, 현실적으로 CPU 코어 수는 한정되어 있다.

### GPU와 딥러닝
GPU는 이름 그대로 3D 이미지 등을 고속으로 렌더링하기 위해 개발된 그래픽 전용 하드웨어이다.
- 3D 렌더링 처리에는 많은 행렬연산이 필요하다.
- 딥러닝 분야가 떠오르면서 GPU 시장은 전례 없을 정도로 큰 성황을 누리고 있다.

### GPU 이용하기
학습을 위해 NVIDIA의 GPU 이용을 전제로 한다.

</br>

## CUDA 프로그래밍